{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution for labels 0-99:\n",
      "Total labels in range: 100\n",
      "Total samples: 129395\n",
      "\n",
      "Per-label breakdown:\n",
      "Label   0 (tench, Tinca tinca                      ):  1300 samples\n",
      "Label   1 (goldfish, Carassius auratus             ):  1300 samples\n",
      "Label   2 (great white shark, white shark, man-eate):  1300 samples\n",
      "Label   3 (tiger shark, Galeocerdo cuvieri         ):  1300 samples\n",
      "Label   4 (hammerhead, hammerhead shark            ):  1300 samples\n",
      "Label   5 (electric ray, crampfish, numbfish, torpe):  1300 samples\n",
      "Label   6 (stingray                                ):  1300 samples\n",
      "Label   7 (cock                                    ):  1300 samples\n",
      "Label   8 (hen                                     ):  1300 samples\n",
      "Label   9 (ostrich, Struthio camelus               ):  1300 samples\n",
      "Label  10 (brambling, Fringilla montifringilla     ):  1300 samples\n",
      "Label  11 (goldfinch, Carduelis carduelis          ):  1300 samples\n",
      "Label  12 (house finch, linnet, Carpodacus mexicanu):  1300 samples\n",
      "Label  13 (junco, snowbird                         ):  1300 samples\n",
      "Label  14 (indigo bunting, indigo finch, indigo bir):  1300 samples\n",
      "Label  15 (robin, American robin, Turdus migratoriu):  1300 samples\n",
      "Label  16 (bulbul                                  ):  1300 samples\n",
      "Label  17 (jay                                     ):  1300 samples\n",
      "Label  18 (magpie                                  ):  1300 samples\n",
      "Label  19 (chickadee                               ):  1300 samples\n",
      "Label  20 (water ouzel, dipper                     ):  1300 samples\n",
      "Label  21 (kite                                    ):  1300 samples\n",
      "Label  22 (bald eagle, American eagle, Haliaeetus l):  1300 samples\n",
      "Label  23 (vulture                                 ):  1300 samples\n",
      "Label  24 (great grey owl, great gray owl, Strix ne):  1300 samples\n",
      "Label  25 (European fire salamander, Salamandra sal):  1300 samples\n",
      "Label  26 (common newt, Triturus vulgaris          ):  1300 samples\n",
      "Label  27 (eft                                     ):  1300 samples\n",
      "Label  28 (spotted salamander, Ambystoma maculatum ):  1300 samples\n",
      "Label  29 (axolotl, mud puppy, Ambystoma mexicanum ):  1300 samples\n",
      "Label  30 (bullfrog, Rana catesbeiana              ):  1300 samples\n",
      "Label  31 (tree frog, tree-frog                    ):  1300 samples\n",
      "Label  32 (tailed frog, bell toad, ribbed toad, tai):  1300 samples\n",
      "Label  33 (loggerhead, loggerhead turtle, Caretta c):  1300 samples\n",
      "Label  34 (leatherback turtle, leatherback, leather):  1300 samples\n",
      "Label  35 (mud turtle                              ):  1300 samples\n",
      "Label  36 (terrapin                                ):  1300 samples\n",
      "Label  37 (box turtle, box tortoise                ):  1300 samples\n",
      "Label  38 (banded gecko                            ):  1300 samples\n",
      "Label  39 (common iguana, iguana, Iguana iguana    ):  1300 samples\n",
      "Label  40 (American chameleon, anole, Anolis caroli):  1300 samples\n",
      "Label  41 (whiptail, whiptail lizard               ):  1300 samples\n",
      "Label  42 (agama                                   ):  1300 samples\n",
      "Label  43 (frilled lizard, Chlamydosaurus kingi    ):  1117 samples\n",
      "Label  44 (alligator lizard                        ):  1300 samples\n",
      "Label  45 (Gila monster, Heloderma suspectum       ):  1300 samples\n",
      "Label  46 (green lizard, Lacerta viridis           ):  1300 samples\n",
      "Label  47 (African chameleon, Chamaeleo chamaeleon ):  1300 samples\n",
      "Label  48 (Komodo dragon, Komodo lizard, dragon liz):  1300 samples\n",
      "Label  49 (African crocodile, Nile crocodile, Croco):  1300 samples\n",
      "Label  50 (American alligator, Alligator mississipi):  1300 samples\n",
      "Label  51 (triceratops                             ):  1266 samples\n",
      "Label  52 (thunder snake, worm snake, Carphophis am):  1300 samples\n",
      "Label  53 (ringneck snake, ring-necked snake, ring ):  1300 samples\n",
      "Label  54 (hognose snake, puff adder, sand viper   ):  1300 samples\n",
      "Label  55 (green snake, grass snake                ):  1300 samples\n",
      "Label  56 (king snake, kingsnake                   ):  1300 samples\n",
      "Label  57 (garter snake, grass snake               ):  1300 samples\n",
      "Label  58 (water snake                             ):  1300 samples\n",
      "Label  59 (vine snake                              ):  1300 samples\n",
      "Label  60 (night snake, Hypsiglena torquata        ):  1300 samples\n",
      "Label  61 (boa constrictor, Constrictor constrictor):  1300 samples\n",
      "Label  62 (rock python, rock snake, Python sebae   ):  1071 samples\n",
      "Label  63 (Indian cobra, Naja naja                 ):  1300 samples\n",
      "Label  64 (green mamba                             ):  1300 samples\n",
      "Label  65 (sea snake                               ):  1300 samples\n",
      "Label  66 (horned viper, cerastes, sand viper, horn):  1300 samples\n",
      "Label  67 (diamondback, diamondback rattlesnake, Cr):  1300 samples\n",
      "Label  68 (sidewinder, horned rattlesnake, Crotalus):  1300 samples\n",
      "Label  69 (trilobite                               ):  1300 samples\n",
      "Label  70 (harvestman, daddy longlegs, Phalangium o):  1300 samples\n",
      "Label  71 (scorpion                                ):  1300 samples\n",
      "Label  72 (black and gold garden spider, Argiope au):  1300 samples\n",
      "Label  73 (barn spider, Araneus cavaticus          ):  1300 samples\n",
      "Label  74 (garden spider, Aranea diademata         ):  1300 samples\n",
      "Label  75 (black widow, Latrodectus mactans        ):  1300 samples\n",
      "Label  76 (tarantula                               ):  1300 samples\n",
      "Label  77 (wolf spider, hunting spider             ):  1300 samples\n",
      "Label  78 (tick                                    ):  1300 samples\n",
      "Label  79 (centipede                               ):  1300 samples\n",
      "Label  80 (black grouse                            ):  1300 samples\n",
      "Label  81 (ptarmigan                               ):  1300 samples\n",
      "Label  82 (ruffed grouse, partridge, Bonasa umbellu):  1300 samples\n",
      "Label  83 (prairie chicken, prairie grouse, prairie):  1300 samples\n",
      "Label  84 (peacock                                 ):  1300 samples\n",
      "Label  85 (quail                                   ):  1300 samples\n",
      "Label  86 (partridge                               ):  1300 samples\n",
      "Label  87 (African grey, African gray, Psittacus er):  1300 samples\n",
      "Label  88 (macaw                                   ):  1300 samples\n",
      "Label  89 (sulphur-crested cockatoo, Kakatoe galeri):  1300 samples\n",
      "Label  90 (lorikeet                                ):  1300 samples\n",
      "Label  91 (coucal                                  ):  1300 samples\n",
      "Label  92 (bee eater                               ):  1300 samples\n",
      "Label  93 (hornbill                                ):  1300 samples\n",
      "Label  94 (hummingbird                             ):  1300 samples\n",
      "Label  95 (jacamar                                 ):  1300 samples\n",
      "Label  96 (toucan                                  ):  1300 samples\n",
      "Label  97 (drake                                   ):  1300 samples\n",
      "Label  98 (red-breasted merganser, Mergus serrator ):  1141 samples\n",
      "Label  99 (goose                                   ):  1300 samples\n"
     ]
    }
   ],
   "source": [
    "# take images_and_labels\n",
    "\n",
    "### CONFIG ###\n",
    "DATA_DIR = \"/home/vladimir_albrekht/projects/img_to_spec/large_files/ILSVRC/imagenet-1k/data\"\n",
    "SPLIT = \"train\"\n",
    "START_LABEL = 0\n",
    "END_LABEL = 100\n",
    "\n",
    "### IMPORTS ###\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "### FUNCTIONS ###\n",
    "def count_labels(data_dir, split, start_label, end_label):\n",
    "    data_dir = Path(data_dir)\n",
    "    parquet_files = sorted(data_dir.glob(f\"{split}-*.parquet\"))\n",
    "    \n",
    "    counter = Counter()\n",
    "    \n",
    "    for pq_file in parquet_files:\n",
    "        table = pq.read_table(pq_file, columns=['label'])\n",
    "        labels = table['label'].to_pylist()\n",
    "        \n",
    "        for label in labels:\n",
    "            if start_label <= label < end_label:\n",
    "                counter[label] += 1\n",
    "    \n",
    "    return counter\n",
    "\n",
    "def get_class_names(data_dir):\n",
    "    parquet_file = next(Path(data_dir).glob(\"train-*.parquet\"))\n",
    "    table = pq.read_table(parquet_file)\n",
    "    hf_meta = json.loads(table.schema.metadata[b'huggingface'])\n",
    "    return hf_meta['info']['features']['label']['names']\n",
    "\n",
    "### MAIN EXECUTION ###\n",
    "class_names = get_class_names(DATA_DIR)\n",
    "label_counts = count_labels(DATA_DIR, SPLIT, START_LABEL, END_LABEL)\n",
    "\n",
    "print(f\"Label distribution for labels {START_LABEL}-{END_LABEL-1}:\")\n",
    "print(f\"Total labels in range: {len(label_counts)}\")\n",
    "print(f\"Total samples: {sum(label_counts.values())}\")\n",
    "print(f\"\\nPer-label breakdown:\")\n",
    "\n",
    "for label in sorted(label_counts.keys()):\n",
    "    print(f\"Label {label:3d} ({class_names[label][:40]:40s}): {label_counts[label]:5d} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIG ###\n",
    "DATA_DIR = \"/home/vladimir_albrekht/projects/img_to_spec/large_files/ILSVRC/imagenet-1k/data\"\n",
    "OUTPUT_DIR = \"/home/vladimir_albrekht/projects/img_to_spec/large_files/ILSVRC/images_10_class\"\n",
    "SPLIT = \"train\"\n",
    "TARGET_LABELS = list(range(10))  # Labels 0-9\n",
    "IMAGE_SIZE = 512\n",
    "MAX_PER_CLASS = None  # None = all, or set a number like 100\n",
    "\n",
    "### IMPORTS ###\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "### FUNCTIONS ###\n",
    "\n",
    "def get_class_names(data_dir):\n",
    "    \"\"\"Get class names from parquet metadata.\"\"\"\n",
    "    parquet_file = next(Path(data_dir).glob(\"train-*.parquet\"))\n",
    "    table = pq.read_table(parquet_file)\n",
    "    hf_meta = json.loads(table.schema.metadata[b'huggingface'])\n",
    "    return hf_meta['info']['features']['label']['names']\n",
    "\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Make class name safe for filesystem.\"\"\"\n",
    "    # Take first part, replace spaces and special chars\n",
    "    name = name.split(',')[0].strip()\n",
    "    name = name.replace(' ', '_').replace('-', '_')\n",
    "    name = ''.join(c for c in name if c.isalnum() or c == '_')\n",
    "    return name[:30]  # Limit length\n",
    "\n",
    "\n",
    "def extract_and_save_images(\n",
    "    data_dir,\n",
    "    output_dir,\n",
    "    split,\n",
    "    target_labels,\n",
    "    image_size=512,\n",
    "    max_per_class=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract images from parquet files, resize to image_size×image_size,\n",
    "    and save organized by class.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = get_class_names(data_dir)\n",
    "    \n",
    "    # Create output directories\n",
    "    label_to_dirname = {}\n",
    "    for label in target_labels:\n",
    "        class_name = sanitize_filename(class_names[label])\n",
    "        dir_name = f\"{label:03d}_{class_name}\"\n",
    "        label_to_dirname[label] = dir_name\n",
    "        (output_dir / dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"Output directories created in {output_dir}\")\n",
    "    for label, dirname in label_to_dirname.items():\n",
    "        print(f\"  Label {label}: {dirname}/\")\n",
    "    \n",
    "    # Track counts per label\n",
    "    counts = {label: 0 for label in target_labels}\n",
    "    \n",
    "    # Find all parquet files\n",
    "    parquet_files = sorted(data_dir.glob(f\"{split}-*.parquet\"))\n",
    "    print(f\"\\nFound {len(parquet_files)} parquet files\")\n",
    "    \n",
    "    # Process each parquet file\n",
    "    for pq_file in tqdm(parquet_files, desc=\"Processing parquet files\"):\n",
    "        # Read table\n",
    "        table = pq.read_table(pq_file, columns=['image', 'label'])\n",
    "        \n",
    "        # Get data\n",
    "        images = table['image'].to_pylist()\n",
    "        labels = table['label'].to_pylist()\n",
    "        \n",
    "        for img_data, label in zip(images, labels):\n",
    "            # Skip if not in target labels\n",
    "            if label not in target_labels:\n",
    "                continue\n",
    "            \n",
    "            # Skip if we have enough for this class\n",
    "            if max_per_class and counts[label] >= max_per_class:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Extract image bytes\n",
    "                if isinstance(img_data, dict) and 'bytes' in img_data:\n",
    "                    img_bytes = img_data['bytes']\n",
    "                elif isinstance(img_data, bytes):\n",
    "                    img_bytes = img_data\n",
    "                else:\n",
    "                    print(f\"Unknown image format: {type(img_data)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Open and resize image\n",
    "                img = Image.open(io.BytesIO(img_bytes))\n",
    "                \n",
    "                # Convert to RGB if necessary\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Resize to square (center crop + resize for better quality)\n",
    "                # Option 1: Simple resize (might distort)\n",
    "                # img = img.resize((image_size, image_size), Image.LANCZOS)\n",
    "                \n",
    "                # Option 2: Center crop to square, then resize (preserves aspect)\n",
    "                w, h = img.size\n",
    "                min_dim = min(w, h)\n",
    "                left = (w - min_dim) // 2\n",
    "                top = (h - min_dim) // 2\n",
    "                img = img.crop((left, top, left + min_dim, top + min_dim))\n",
    "                img = img.resize((image_size, image_size), Image.LANCZOS)\n",
    "                \n",
    "                # Save\n",
    "                dir_name = label_to_dirname[label]\n",
    "                filename = f\"{counts[label]:05d}.jpg\"\n",
    "                save_path = output_dir / dir_name / filename\n",
    "                img.save(save_path, 'JPEG', quality=95)\n",
    "                \n",
    "                counts[label] += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Check if we have enough for all classes\n",
    "        if max_per_class and all(c >= max_per_class for c in counts.values()):\n",
    "            print(\"\\nReached max_per_class for all labels, stopping early.\")\n",
    "            break\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "### MAIN EXECUTION ###\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"IMAGENET IMAGE EXTRACTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    counts = extract_and_save_images(\n",
    "        data_dir=DATA_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        split=SPLIT,\n",
    "        target_labels=TARGET_LABELS,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        max_per_class=MAX_PER_CLASS\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total = 0\n",
    "    for label in sorted(counts.keys()):\n",
    "        class_names = get_class_names(DATA_DIR)\n",
    "        print(f\"Label {label:3d} ({class_names[label][:30]:30s}): {counts[label]:5d} images\")\n",
    "        total += counts[label]\n",
    "    \n",
    "    print(f\"\\nTotal images extracted: {total}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## Структура Результата\n",
    "# ```\n",
    "# /home/vladimir_albrekht/projects/img_to_spec/large_files/ILSVRC/images_10_class/\n",
    "# ├── 000_tench/\n",
    "# │   ├── 00000.jpg\n",
    "# │   ├── 00001.jpg\n",
    "# │   └── ... (1300 images)\n",
    "# ├── 001_goldfish/\n",
    "# │   ├── 00000.jpg\n",
    "# │   └── ...\n",
    "# ├── 002_great_white_shark/\n",
    "# │   └── ...\n",
    "# ├── 003_tiger_shark/\n",
    "# │   └── ...\n",
    "# ├── 004_hammerhead/\n",
    "# │   └── ...\n",
    "# ├── 005_electric_ray/\n",
    "# │   └── ...\n",
    "# ├── 006_stingray/\n",
    "# │   └── ...\n",
    "# ├── 007_cock/\n",
    "# │   └── ...\n",
    "# ├── 008_hen/\n",
    "# │   └── ...\n",
    "# └── 009_ostrich/\n",
    "#     └── ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading repository rhasspy/piper-voices...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f954111042ad4a3089eb17b5090147b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe82218b82cc477c97f46baf75467b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching ... files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository downloaded to /scratch/vladimir_albrekht/projects/i2m/to_revise/piper_tts\n"
     ]
    }
   ],
   "source": [
    "# 1. download\n",
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub import login\n",
    "import dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "dotenv.load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "\n",
    "repo_id = \"rhasspy/piper-voices\"\n",
    "local_dir = Path(\"piper_tts\").resolve()\n",
    "\n",
    "def download_model_repo(repo_id, local_dir):\n",
    "    print(f\"Downloading repository {repo_id}...\")\n",
    "    snapshot_download(\n",
    "        repo_id=repo_id,\n",
    "        allow_patterns=[\"en/en_US/*\"],\n",
    "        local_dir=str(local_dir)\n",
    "    )\n",
    "    print(f\"Repository downloaded to {local_dir}\")\n",
    "\n",
    "download_model_repo(repo_id, local_dir)\n",
    "\n",
    "# # 2. generate speech\n",
    "# import wave\n",
    "# from piper import PiperVoice\n",
    "\n",
    "# # Simple CPU TTS inference\n",
    "\n",
    "# voice_path = \"piper_tts/en/en_US/amy/medium/en_US-amy-medium.onnx\"\n",
    "# text = \"Сәлеметсіз бе, бұл мысал сөйлем.\"\n",
    "# output_wav = \"audio.wav\"\n",
    "\n",
    "# voice = PiperVoice.load(voice_path, use_cuda=False)\n",
    "\n",
    "# with wave.open(output_wav, \"wb\") as wav_file:\n",
    "#     voice.synthesize_wav(text, wav_file)\n",
    "\n",
    "# print(\"Done:\", output_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUDIO GENERATION WITH PIPER TTS\n",
      "============================================================\n",
      "Loading voice from /scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/piper_tts/en/en_US/amy/medium/en_US-amy-medium.onnx...\n",
      "✓ Voice loaded\n",
      "\n",
      "Label 0: 000_tench\n",
      "  Text: \"A tench, a freshwater fish\"\n",
      "  ✓ Saved: description.wav (2.21 sec, 22050 Hz)\n",
      "\n",
      "Label 1: 001_goldfish\n",
      "  Text: \"A goldfish, bright orange fish\"\n",
      "  ✓ Saved: description.wav (2.33 sec, 22050 Hz)\n",
      "\n",
      "Label 2: 002_great_white_shark\n",
      "  Text: \"A great white shark, ocean predator\"\n",
      "  ✓ Saved: description.wav (2.48 sec, 22050 Hz)\n",
      "\n",
      "Label 3: 003_tiger_shark\n",
      "  Text: \"A tiger shark with dark stripes\"\n",
      "  ✓ Saved: description.wav (2.35 sec, 22050 Hz)\n",
      "\n",
      "Label 4: 004_hammerhead\n",
      "  Text: \"A hammerhead shark with unique head\"\n",
      "  ✓ Saved: description.wav (2.38 sec, 22050 Hz)\n",
      "\n",
      "Label 5: 005_electric_ray\n",
      "  Text: \"An electric ray with electric shocks\"\n",
      "  ✓ Saved: description.wav (2.67 sec, 22050 Hz)\n",
      "\n",
      "Label 6: 006_stingray\n",
      "  Text: \"A stingray gliding through water\"\n",
      "  ✓ Saved: description.wav (2.17 sec, 22050 Hz)\n",
      "\n",
      "Label 7: 007_cock\n",
      "  Text: \"A rooster with colorful feathers\"\n",
      "  ✓ Saved: description.wav (2.28 sec, 22050 Hz)\n",
      "\n",
      "Label 8: 008_hen\n",
      "  Text: \"A hen pecking at seeds\"\n",
      "  ✓ Saved: description.wav (1.87 sec, 22050 Hz)\n",
      "\n",
      "Label 9: 009_ostrich\n",
      "  Text: \"An ostrich, the largest bird\"\n",
      "  ✓ Saved: description.wav (2.38 sec, 22050 Hz)\n",
      "\n",
      "============================================================\n",
      "✓ ALL AUDIO FILES GENERATED\n",
      "  Output: /scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/audios_10_class\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# generate_audio.py\n",
    "\n",
    "import wave\n",
    "from pathlib import Path\n",
    "from piper import PiperVoice\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "\n",
    "### CONFIG ###\n",
    "VOICE_PATH = \"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/piper_tts/en/en_US/amy/medium/en_US-amy-medium.onnx\"\n",
    "OUTPUT_DIR = Path(\"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/audios_10_class\")\n",
    "USE_CUDA = False\n",
    "\n",
    "### CLASS DESCRIPTIONS (~2 sec each) ###\n",
    "CLASS_DESCRIPTIONS = {\n",
    "    0: \"A tench, a freshwater fish\",                        # было 3.52 → ~1.5 sec\n",
    "    1: \"A goldfish, bright orange fish\",                    # было 3.10 → ~1.5 sec\n",
    "    2: \"A great white shark, ocean predator\",               # 2.93 ✓ OK\n",
    "    3: \"A tiger shark with dark stripes\",                   # было 3.11 → ~2 sec\n",
    "    4: \"A hammerhead shark with unique head\",               # 2.87 ✓ OK\n",
    "    5: \"An electric ray with electric shocks\",              # было 3.25 → ~2 sec\n",
    "    6: \"A stingray gliding through water\",                  # 2.41 ✓ OK\n",
    "    7: \"A rooster with colorful feathers\",                  # 2.67 ✓ OK\n",
    "    8: \"A hen pecking at seeds\",                            # 2.55 ✓ OK\n",
    "    9: \"An ostrich, the largest bird\",                      # было 3.49 → ~2 sec\n",
    "}\n",
    "\n",
    "CLASS_DIRNAMES = {\n",
    "    0: \"000_tench\",\n",
    "    1: \"001_goldfish\",\n",
    "    2: \"002_great_white_shark\",\n",
    "    3: \"003_tiger_shark\",\n",
    "    4: \"004_hammerhead\",\n",
    "    5: \"005_electric_ray\",\n",
    "    6: \"006_stingray\",\n",
    "    7: \"007_cock\",\n",
    "    8: \"008_hen\",\n",
    "    9: \"009_ostrich\",\n",
    "}\n",
    "\n",
    "### MAIN ###\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"AUDIO GENERATION WITH PIPER TTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load Piper voice\n",
    "    print(f\"Loading voice from {VOICE_PATH}...\")\n",
    "    voice = PiperVoice.load(VOICE_PATH, use_cuda=USE_CUDA)\n",
    "    print(\"✓ Voice loaded\")\n",
    "    \n",
    "    # Create output directory\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate audio for each class\n",
    "    for label, description in CLASS_DESCRIPTIONS.items():\n",
    "        dirname = CLASS_DIRNAMES[label]\n",
    "        class_audio_dir = OUTPUT_DIR / dirname\n",
    "        class_audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        output_path = class_audio_dir / \"description.wav\"\n",
    "        \n",
    "        print(f\"\\nLabel {label}: {dirname}\")\n",
    "        print(f\"  Text: \\\"{description}\\\"\")\n",
    "        \n",
    "        # Generate audio\n",
    "        with wave.open(str(output_path), \"wb\") as wav_file:\n",
    "            voice.synthesize_wav(description, wav_file)\n",
    "        \n",
    "        # Check duration\n",
    "        data, sr = sf.read(output_path)\n",
    "        duration = len(data) / sr\n",
    "        print(f\"  ✓ Saved: {output_path.name} ({duration:.2f} sec, {sr} Hz)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ ALL AUDIO FILES GENERATED\")\n",
    "    print(f\"  Output: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # verify_audio.py\n",
    "\n",
    "# import torchaudio\n",
    "# from pathlib import Path\n",
    "\n",
    "# AUDIO_DIR = Path(\"/home/vladimir_albrekht/projects/img_to_spec/large_files/ILSVRC/audio_10_class\")\n",
    "\n",
    "# print(\"Audio Duration Check:\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# total_duration = 0\n",
    "# for class_dir in sorted(AUDIO_DIR.iterdir()):\n",
    "#     if not class_dir.is_dir():\n",
    "#         continue\n",
    "    \n",
    "#     audio_file = class_dir / \"description.wav\"\n",
    "#     if audio_file.exists():\n",
    "#         waveform, sr = torchaudio.load(str(audio_file))\n",
    "#         duration = waveform.shape[1] / sr\n",
    "#         total_duration += duration\n",
    "        \n",
    "#         status = \"✓\" if 1.5 <= duration <= 3.0 else \"⚠️\"\n",
    "#         print(f\"{status} {class_dir.name}: {duration:.2f} sec @ {sr} Hz\")\n",
    "\n",
    "# print(\"=\" * 50)\n",
    "# print(f\"Average duration: {total_duration / 10:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING pairs.json\n",
      "============================================================\n",
      "Found 10 class directories\n",
      "\n",
      "000_tench: 1300 images\n",
      "001_goldfish: 1300 images\n",
      "002_great_white_shark: 1300 images\n",
      "003_tiger_shark: 1300 images\n",
      "004_hammerhead: 1300 images\n",
      "005_electric_ray: 1300 images\n",
      "006_stingray: 1300 images\n",
      "007_cock: 1300 images\n",
      "008_hen: 1300 images\n",
      "009_ostrich: 1300 images\n",
      "\n",
      "============================================================\n",
      "✓ Created /scratch/vladimir_albrekht/projects/i2m/src/data/pairs.json\n",
      "  Total pairs: 13000\n",
      "============================================================\n",
      "\n",
      "Sample entries:\n",
      "  00000.jpg → 000_tench/description.wav\n",
      "  00001.jpg → 000_tench/description.wav\n",
      "  00000.jpg → 005_electric_ray/description.wav\n",
      "  01299.jpg → 009_ostrich/description.wav\n"
     ]
    }
   ],
   "source": [
    "# create_pairs_json.py\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "### CONFIG ###\n",
    "IMAGES_DIR = Path(\"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/images_10_class\")\n",
    "AUDIO_DIR = Path(\"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/audios_10_class\")\n",
    "OUTPUT_PATH = Path(\"/scratch/vladimir_albrekht/projects/i2m/src/data/pairs.json\")\n",
    "\n",
    "### MAIN ###\n",
    "def create_pairs_json():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CREATING pairs.json\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    # Get all class directories\n",
    "    class_dirs = sorted([d for d in IMAGES_DIR.iterdir() if d.is_dir()])\n",
    "    \n",
    "    print(f\"Found {len(class_dirs)} class directories\\n\")\n",
    "    \n",
    "    for class_dir in class_dirs:\n",
    "        class_name = class_dir.name\n",
    "        \n",
    "        # Find corresponding audio file\n",
    "        audio_path = AUDIO_DIR / class_name / \"description.wav\"\n",
    "        \n",
    "        if not audio_path.exists():\n",
    "            print(f\"⚠️ No audio for {class_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Get all images in this class\n",
    "        image_files = sorted(class_dir.glob(\"*.jpg\"))\n",
    "        \n",
    "        print(f\"{class_name}: {len(image_files)} images\")\n",
    "        \n",
    "        # Create pairs (each image paired with the class audio)\n",
    "        for img_path in image_files:\n",
    "            pairs.append({\n",
    "                \"image\": str(img_path),\n",
    "                \"audio\": str(audio_path)\n",
    "            })\n",
    "    \n",
    "    # Save pairs.json\n",
    "    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(OUTPUT_PATH, 'w') as f:\n",
    "        json.dump(pairs, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"✓ Created {OUTPUT_PATH}\")\n",
    "    print(f\"  Total pairs: {len(pairs)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nSample entries:\")\n",
    "    for i in [0, 1, len(pairs)//2, -1]:\n",
    "        p = pairs[i]\n",
    "        print(f\"  {Path(p['image']).name} → {Path(p['audio']).parent.name}/{Path(p['audio']).name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_pairs_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf, torch, torchaudio\n",
    "\n",
    "x, sr = sf.read(\"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/audios_10_class/000_tench/description.wav\", dtype=\"float32\")\n",
    "x = torch.from_numpy(x).unsqueeze(0) if x.ndim == 1 else torch.from_numpy(x).mean(dim=1, keepdim=True).T\n",
    "y = torchaudio.transforms.Resample(sr, 24000)(x).squeeze(0).numpy()\n",
    "sf.write(\"/scratch/vladimir_albrekht/projects/i2m/large_files/ILSVRC_images_10_class/audios_10_class/000_tench/temp.wav\", y, 24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2m",
   "language": "python",
   "name": "i2m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
